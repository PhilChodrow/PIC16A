{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Files\n",
    "\n",
    "### Before the start of this video: Make sure the file palmer_penguins.csv is in the same folder as this notebook\n",
    "\n",
    "In this lecture, we'll discuss some basic methods for reading and writing files. Our primary focus today will be on text. We'll also briefly discuss reading *delimited files*, such as `.csv`s, but we'll spend more time on these when we work with rectangular data using the `pandas` module. \n",
    "\n",
    "## Writing Data\n",
    "\n",
    "Whenever we interact with a file -- including creating, writing, and reading -- we will use the `open()` function. We need to specify both the path to the file and the *mode* of interaction. For example, `\"w\"` specifies that we want to *write* to the file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"my_file.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look, we can see that a file called 'my_file.txt' has been created. Addidttionally the variable f has been assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='my_file.txt' mode='w' encoding='cp1252'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"If you can dodge a wrench, you can dodge a ball\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text won't actually appear in the file until close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the connection is closed, we can't write any more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-242d8e65216f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dodge dip dive duck and dodge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "f.write(\"Dodge dip dive duck and dodge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should **always** close files after you have opened them. However, there is a nice syntactical way to avoid having to remember to do this, using the `with` keyword: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"better_way.txt\", \"w\") as f:\n",
    "    f.write(\"Duck dip dive duck and dodge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the `with` keyword as temporarily assigning the name `f` within a local scope. Once the local scope terminates, the variables created within that scope are discarded. This process has the convenient effect of automatically closing `f` for us. You should usually use `with` rather than `open()` and `f.close()` unless there are concrete requirements otherwise. \n",
    "\n",
    "A very common pattern is to loop over data and write it line-by-line to a file. Here's an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Capitals={\n",
    "    \"MA\":\"Boston\",\n",
    "    \"MI\":\"Lansing\",\n",
    "    \"CA\":\"Sacremento\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"capitals.txt\",\"w\") as f:\n",
    "    for key,val in Capitals.items():\n",
    "        f.write(val +\" is the capital of \"+ key+\".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the `\"w\"` argument to `open()` will erase an existing file `capitals.txt` if one exists. To append to the file, use mode `\"a\"` instead:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"capitals.txt\",\"a\") as f:\n",
    "    f.write(\"Raleigh is the capital of NC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "Reading data is not difficult, provided that you can remember iterators. The `f.readline()` method returns the current line of the file and then advances to the next line, very similar to the `__next__()` method of iterators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston is the capital of MA.\n",
      "Lansing is the capital of MI.\n"
     ]
    }
   ],
   "source": [
    "with open(\"capitals.txt\", \"r\") as f:\n",
    "    print(f.readline(),end=\"\")\n",
    "    print(f.readline(),end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston is the capital of MA.\n",
      "Lansing is the capital of MI.\n",
      "Sacremento is the capital of CA.\n",
      "Raleigh is the capital of NC"
     ]
    }
   ],
   "source": [
    "with open(\"capitals.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Files\n",
    "\n",
    "`CSV` standands for \"comma-separated values,\" and it is a common format for representing tabular data. A raw `CSV` file might look like this: \n",
    "\n",
    "```csv\n",
    "\n",
    "\"Boston\", \"Massachusetts\", \"The Bay State\" \n",
    "\"Lansing\", \"Michigan\", \"The Great Lakes State\"\n",
    "\"Sacremento\", \"California\", \"The Golden State\"\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "\n",
    "Python offers a `csv` module that offers some utilities for reading and writing `CSV` files. For example, let's take a quick peek at the [Palmer penguins] data set, which were collected by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a member of the [Long Term Ecological Research Network](https://lternet.edu/). I downloaded these data from [Kaggle](https://www.kaggle.com/), an excellent source of interesting data sets. If you haven't already, please make sure that the file `palmer_penguins.csv` is in the same directory as this notebook. \n",
    "\n",
    "<figure class=\"image\" style=\"width:50%\">\n",
    "  <img src=\"https://allisonhorst.github.io/palmerpenguins/man/figures/lter_penguins.png\" alt=\"Three stylized penguins, one each of the species Adelie, Gentoo, and Chinstrap, with labels above their heads and patches of color behind them.\">\n",
    "  <figcaption><i>Illustrations of the penguins in the Palmer Penguins data set, by Allison Horst.</i></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read the file we need to import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is long, so let's look at the first 10 rows and the first five entries of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studyName', 'Sample Number', 'Species', 'Region', 'Island']\n",
      "['PAL0708', '1', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '2', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '3', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '4', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '5', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '6', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '7', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '8', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '9', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open (\"palmer_penguins.csv\", \"r\") as f:\n",
    "    reader=csv.reader(f)\n",
    "    for row in list(reader)[0:10]:\n",
    "        print(row[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write new CSV files. For example, let's make a subset file that only includes Adelie Penguins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"palmer_penguins.csv\", \"r\") as original: \n",
    "    with open(\"palmer_penguins_subset.csv\", \"w\") as subset: \n",
    "        reader = csv.reader(original)\n",
    "        writer = csv.writer(subset)\n",
    "        \n",
    "        for row in reader: \n",
    "            if row[2] == \"Adelie Penguin (Pygoscelis adeliae)\":\n",
    "                writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the file `palmer_penguins_subset.csv` and observe that all rows in the new data are Adelie penguins. \n",
    "\n",
    "While it is possible to use the `csv` module for reading and manipulating tabular data, we will see much more flexible and powerful methods when we introduce the *data frames* paradigm via the `pandas` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
