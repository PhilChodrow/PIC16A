{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "\n",
    "Unlike previous homework assignments, this homework is **completed as a group** and **submitted on CCLE.** In other words, it's similar to an extended Discussion Activity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0\n",
    "\n",
    "It is highly recommended that you work with your group to fully complete the previous Discussion assignments related to the project this week, as all of these are directly helpful for your project submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "In your project, you are required to demonstrate the use of decision trees and multinomial logistic regression classifiers. Groups of three must also demonstrate the use of one additional model. In this homework assignment, you will write a detailed report that will largely fulfill this requirement. \n",
    "\n",
    "Choose one machine learning model, other than decision trees and multinomial logistic regression (unless you are a group of 2 -- see below). Some possibilities include, but are not limited to: \n",
    "\n",
    "- Support vector classifiers (`sklearn.svm.SVC`). Complexity parameter is called `gamma`. Higher values create more complex models)\n",
    "- K-nearest-neighbor classifiers (`sklearn.neighbors.KNeighborsClassifier`). Complexity parameter is called `n_neighbors`. Higher values create less complex models. When working with KNN models, it is helpful to standardize your data columns first. For this purpose, `sklearn.preprocessing.StandardScaler` can be used. \n",
    "- Multilayer perceptron classifier, a kind of neural network (`sklearn.neural_network.MLPClassifier`). The complexity is controlled by the number of neurons and layers, as specified by the `hidden_layer_sizes` parameter -- more neurons and layers correspond to more complex models. \n",
    "\n",
    "You should consult the documentation for these models, which is available online or via `?`. \n",
    "\n",
    "\n",
    "#### Groups of 2\n",
    "\n",
    "If you are a group of 2, you are not required to use an additional model and may instead use multinomial logistic regression for this assignment. Please note this in your submission. \n",
    "\n",
    "- Multinomial logistic regression (`sklearn.linear_model.LogisticRegression`). The complexity is controlled by `C`, the inverse regularization strength. Larger values of `C` correspond to more complex models. \n",
    "\n",
    "### Instructions\n",
    "\n",
    "Replicate and expand the pipeline from Discussion 15, substituting out decision trees for your chosen classifier. In particular, you should: \n",
    "\n",
    "1. **Load** the data. \n",
    "2. **Split the data** into training and test sets. \n",
    "3. Write one or more functions to **clean and transform the data** as needed. You should add comments and function docstrings as appropriate to describe to your reader what you are doing and why. Apply your functions to the training and test sets. \n",
    "4. **Select 3 columns (features)** from the data. You are required to use at least one qualitative feature (like Island or Sex). We saw one way of doing this \"by hand\" during a previous Live Lecture, but there are many other approaches as well. You may wish to delegate one group member to do some research on the topic of \"feature selection in Python with sklearn\". \n",
    "4. **Use cross-validation** to estimate optimal model complexity (*Note*: cross-validation is also an acceptable way to perform feature selection -- you may use it above, but you are required to use it here). \n",
    "5. Having selected your features and an optimal complexity, **evaluate your model on the test set.** \n",
    "6. **Inspect** a few instances in which your trained model gave the wrong answer on the test set. Explain why your model was \"tricked\" in this case? Create and comment on a confusion matrix -- [check Monday's lecture notes](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16A/blob/master/content/ML/digits.ipynb) for an example. \n",
    "7. **Plot the decision regions** for your model. These are covered in a recent live lecture, and code required to construct them is below. The horizontal and vertical axes should be the two quantitative predictor variables that you selected. Create a separate plot for each possible value of the qualitative predictor variable that you selected. For example, if you chose `Sex` as your qualitative variable, you should show two plots, with the decision regions for Female and Male penguins separately. Add appropriate axis labels and any other measures required to make your plots look professional. Add commentary to contextualize the mistakes that your model made. \n",
    "    - You are welcome to use the [code from live lecture](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16A/blob/master/live_lectures/live-lecture-22.ipynb) for this purpose. A common pitfall when using code for manual decision regions is re-training a model (using `model.fit()`) once for each plot. You should ensure that your model is only trained once, and that its predictions are then extracted for each plot. \n",
    "    - Another good approach is to use a built-in function for decision regions, like from the package `mlxtend` ([link](https://rasbt.github.io/mlxtend/installation/)). You can install this package by running the code `conda install mlxtend` in a Python code cell. (*Note*: this isn't really the recommended way to install packages in Anaconda, but because we haven't covered environment management it's ok to do here). \n",
    "\n",
    "Throughout, add helpful explanation for your reader. For example, you should explain the idea behind cross-validation; anything you are able to learn about how your model works; how to interpret the optimal complexity parameter; and why your model went wrong in certain cases.  \n",
    "\n",
    "### Additional Specifications\n",
    "\n",
    "This homework will be graded by me personally, and will be graded using a rubric very similar to that used for the final project. I'll also give you some feedback indicating how you can improve. To get the most benefit out of this feedback, you should **treat this homework as a rehearsal for the full project.** \n",
    "\n",
    "Your solution should **not** fit in a single code cell -- a good, readable, and adequately-explained solution will likely require at least one code cell for each of the eight steps above. Make sure that there is plenty of surrounding text explanation and comments. Add code cells and plenty of markdown cells as needed. You can also use section headers with `###` to organize your work. \n",
    "\n",
    "Your comments and explanation should be written to an imaginary reader who has never encountered the Palmer Penguins data set before, and knows less about machine learning than you do. Explain your steps. Why train-test split? Why cross-validation? Why decision regions? And so on. If you'd like, imagine that you are writing to a time-traveller version of you from two weeks ago. \n",
    "\n",
    "It is not necessary to submit the HW on a copy of this notebook -- you may create and submit a fresh notebook if you wold like. Regardless, \n",
    "\n",
    "#### You are required to include a Group Contributions Statement on this HW. \n",
    "\n",
    "## Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
