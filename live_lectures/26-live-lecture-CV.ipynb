{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5d7dca-d6da-434e-8d5c-42f56cffadf4",
   "metadata": {},
   "source": [
    "## DRY Cross Validation\n",
    "\n",
    "Recall that \"DRY\" stands for \"**D**on't **R**epeat **Y**ourself.\" In this set of notes, we'll see how to write a function that can partially automate the selection of complexity parameters. \n",
    "\n",
    "In a recent Discussion, you wrote code to select complexity parameters for your model. Your code might have looked something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af5dcfa1-c79f-46d8-ba50-ea7550090312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree, preprocessing, linear_model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "url = \"https://philchodrow.github.io/PIC16A/datasets/palmer_penguins.csv\"\n",
    "penguins = pd.read_csv(url)\n",
    "penguins = penguins[['Species', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex']]\n",
    "\n",
    "penguins = penguins.dropna()\n",
    "penguins = penguins[penguins[\"Sex\"] != \".\"]\n",
    "\n",
    "X = penguins.drop(['Species'], axis = 1)\n",
    "y = penguins['Species']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "X['Sex'] = le.fit_transform(X['Sex'])\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89072783-536f-4aa5-b0ed-3d3962a2b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth is 24\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for d in range(1,30):\n",
    "    T = tree.DecisionTreeClassifier(max_depth = d)\n",
    "    cv_score = cross_val_score(T, X, y, cv=10).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_depth = d\n",
    "        best_score = cv_score\n",
    "print(\"best depth is \" + str(best_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0f930-34e9-44a4-8d04-738aa8c08916",
   "metadata": {},
   "source": [
    "That's all well and good for handling one model, but I've asked you to do three! How can we make this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47af15-780b-421d-8adf-b8ba013c845c",
   "metadata": {},
   "source": [
    "## Version 1\n",
    "\n",
    "First, let's write a function that will allow us to select a depth for a decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c357fe82-9e2a-40cc-85a2-6337d43e9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_DT_depth(X, y, possible_depths):\n",
    "    best_score = 0\n",
    "    for d in possible_depths:\n",
    "        T = tree.DecisionTreeClassifier(max_depth = d)\n",
    "        cv_score = cross_val_score(T, X, y, cv=10).mean()\n",
    "        if cv_score > best_score:\n",
    "            best_depth = d\n",
    "            best_score = cv_score\n",
    "    \n",
    "    return best_depth, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7da51f0b-05d1-46e8-bf72-269ae8124e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth was 22 with score 0.8017825311942959.\n"
     ]
    }
   ],
   "source": [
    "depth, score = select_DT_depth(X, y, range(1, 30))\n",
    "print(\"Best depth was \" + str(depth) + \" with score \" + str(score) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5cad7d-5e40-4596-9927-118ca882f7ef",
   "metadata": {},
   "source": [
    "This works just fine, but we have an issue: other models have *different* complexity parameters. How can we write a function that will work both for decision trees, where the complexity parameter is called `max_depth`, and for logistic regression, where the complexity parameter is called `C`? \n",
    "\n",
    "As a warmup, let's consider this mini-problem:\n",
    "\n",
    "> Suppose we have a function `g` that accepts multiple keyword arguments. Write a function `f` such that \n",
    "\n",
    "```python\n",
    "f(\"captain\", \"Burnham\") == g(captain = \"Burnham\") \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Hint**: Week 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28c97e-9ef3-4fe9-a96c-a79ac6d740c7",
   "metadata": {},
   "source": [
    "Ok, now let's use this idea to write a simple function for selecting a model complexity from some supplied possibilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02fd8f85-33d1-4942-963b-a1c281fefa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_complexity(model, X, y, complexity_kw, possible_complexities, **kwargs):\n",
    "    \n",
    "    best_score = 0\n",
    "    for C in possible_complexities:\n",
    "        comp = {complexity_kw : C}\n",
    "        m = model(**comp, **kwargs)\n",
    "        \n",
    "        cv_score = cross_val_score(m, X, y, cv=10).mean()\n",
    "        if cv_score > best_score:\n",
    "            best_C = C\n",
    "            best_score = cv_score\n",
    "            \n",
    "    return best_C, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a790e12f-4eeb-46be-a746-67ee3bdb5cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 0.7746880570409982)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_complexity(linear_model.LogisticRegression, X, y, \"C\", 10.0**np.arange(-5, 5), solver = \"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7ecc5f6-4de1-4f2a-83c8-e713d2a745de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0.7958110516934046)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_complexity(tree.DecisionTreeClassifier, X, y, \"max_depth\", range(1, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fadcad-d3e5-4139-9d3c-f0469caef873",
   "metadata": {},
   "source": [
    "We can even use this for cases in which the possible complexity parameters are structured objects, like lists or tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e6dd613-6af2-41cd-a002-d8dd23bcc5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 10, 100), 0.5705882352941176)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neural_network\n",
    "from itertools import product\n",
    "\n",
    "layer_sizes = [10, 50, 100]\n",
    "layer_configs = product(layer_sizes, layer_sizes, layer_sizes) # each parameter is actually a spec for 3 layers\n",
    "\n",
    "select_complexity(neural_network.MLPClassifier, X, y, \"hidden_layer_sizes\", layer_configs, solver = \"adam\", max_iter = 1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
