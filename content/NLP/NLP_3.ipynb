{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "*Sentiment analysis* is the task of evaluating whether a given passage of text is primarily \"positive\" or \"negative.\" The meanings of these terms can change in context. For example, a \"positive\" product review would indicate that the customer likes the product, whereas a \"positive\" tweet might just indicate that the user is happy that day. \n",
    "\n",
    "In this lecture, we'll discuss how familiar machine learning tools can allow us to perform sentiment analysis on unstructured text. \n",
    "\n",
    "Our data set for this task comes from the `nltk` package again. It's a set of movie reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# need to run this line the first time\n",
    "# nltk.download('movie_reviews')\n",
    "\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `movie_reviews` object allows us to read in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today, the two most important methods of this object are `fileids()` and `raw()`. The first method will allow us to locate the files on disk in which the movie reviews are contained, and the second method will allow us to then obtain the full text of the reviews from the file path. \n",
    "\n",
    "Let's first look at the fileids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = movie_reviews.fileids()[0]\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each review is contained in its own file, in one of two folders. The `neg` folder contains negative reviews, while the `pos` folder contains positive reviews. \n",
    "\n",
    "Once we have picked fixed a file path, we can then use the `raw()` method to extract the raw text of the movie review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.raw(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to think: how can we read in the complete data set? \n",
    "\n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "\n",
    "A `for`-loop would be one way. In this approach, we would create an empty list to hold the review texts, iterate over the list of file paths, and populate the list for texts as we go. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = []\n",
    "for p in movie_reviews.fileids():\n",
    "    raw_texts.append(movie_reviews.raw(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does work, but it requires three lines and still leaves us with the task of bringing the texts into a format (like a data frame) that we know how to work with. \n",
    "\n",
    "Using the `apply` method from `pandas` gives us a much more efficient way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame whose only column contains the fileids\n",
    "df = pd.DataFrame({'fileid' : movie_reviews.fileids()})\n",
    "\n",
    "# create a new column by applying the movie_reviews.raw()\n",
    "# method to each entry of df['fileid']\n",
    "df['raw_text'] = df['fileid'].apply(movie_reviews.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have read in the data. Do we have what we need for sentiment analysis? \n",
    "\n",
    "Not quite yet, but we're close! In this lecture, we'll treat sentiment analysis as a form of *classification*: our aim is to build a machine learning model that we can use to predict whether a given text is positive or negative. For this approach, we are going to need both target and predictor variables. Fortunately, we know how to obtain both of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the text came from the pos folder. \n",
    "df['is_good'] = df['fileid'].str.split(\"/\").str.get(0) == \"pos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use tools from before to create a term-document matrix. This time, we treat each movie review as a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(max_df=.2, min_df=30, stop_words='english')\n",
    "\n",
    "counts = vec.fit_transform(df['raw_text'])\n",
    "count_df = pd.DataFrame(counts.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, count_df), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now successfully read in and prepared our data. \n",
    "\n",
    "---\n",
    "\n",
    "# On to Sentiment Analysis\n",
    "\n",
    "These steps should be pretty familiar. We are going to split our data into training and test sets, create a logistic classifier, and evaluate the logistic classifier on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.4)\n",
    "\n",
    "X_train = train.drop(['fileid', 'raw_text', 'is_good'], axis = 1)\n",
    "y_train = train['is_good']\n",
    "\n",
    "X_test = test.drop(['fileid', 'raw_text', 'is_good'], axis = 1)\n",
    "y_test = test['is_good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "LR.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(LR, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model perfectly fits the test data, but based on CV it looks like our predictive accuracy might only be around 80%. This looks like overfitting, which makes sense -- overfitting is a very common problem when we have many predictor columns (lots of words) and not that many data observations. \n",
    "\n",
    "There are multiple ways to address this. In this lecture, let's use the regularization parameter `C`, which controls model complexity in logistic regression. While one could be more systematic about this, here's a simple little loop: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in np.linspace(0.005, 0.05, 10):\n",
    "    print(str(np.round(C, 4)), end = \": \")\n",
    "    LR = LogisticRegression(C = C)\n",
    "    cv_score = cross_val_score(LR, X_train, y_train, cv = 5).mean()\n",
    "    print(np.round(cv_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we can improve our estimated accuracy to nearly 82% using C = 0.02 or so. Let's do that and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C = 0.02)\n",
    "LR.fit(X_train, y_train)\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our simple logistic model is able to correctly identify vs. negative movie reviews about 82% of the time. Not bad! \n",
    "\n",
    "However, we're not done yet. \n",
    "\n",
    "One of the primary purposes of sentiment analysis is to determine which words carry positive or negative associations. It is common to assign scores to each word that govern how positive or negative they are. We can do this using the coefficients of the logistic model. First, let's make a data frame of the words and their scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\"coef\" : LR.coef_[0], \"word\" : X_train.columns})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's sort the data frame to see the most negative words according to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values('coef', ascending = True).head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That makes sense! What about the most positive words? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values('coef', ascending = False).head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also looks pretty logical. We can conclude that our model has had some success in learning which words have positive and negative meanings. \n",
    "\n",
    "Of course, the story isn't over: there are many different models that can be used for sentiment analysis, some of which highlight different features. \n",
    "\n",
    "Finally, the combination of term-document extraction with classification models isn't just for sentiment analysis! Essentially the same pipeline can work to produce a functioning spam classifier, in which a \"negative\" set of text is spam and a \"positive\" set of text is a legitimate email. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
