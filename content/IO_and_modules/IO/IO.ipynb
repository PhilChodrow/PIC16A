{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Files\n",
    "\n",
    "In this lecture, we'll discuss some basic methods for reading and writing files. Our primary focus today will be on text. We'll also briefly discuss reading *delimited files*, such as `.csv`s, but we'll spend more time on these when we work with rectangular data using the `pandas` module. \n",
    "\n",
    "## Writing Data\n",
    "\n",
    "Whenever we interact with a file -- including creating, writing, and reading -- we will use the `open()` function. We need to specify both the path to the file and the *mode* of interaction. For example, `\"w\"` specifies that we want to *write* to the file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"my_file.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file explorer, we can see that `my_file.txt` has been created! Additionally, a variable `f` has been assigned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='my_file.txt' mode='w' encoding='UTF-8'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some text to `f`. The return value of `write()` is the number of characters in the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"To boldly go\\n\") # \\n starts a newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after calling `f.write()`, we won't be able to inspect the new text we've written until we *close* the connection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've closed the connection, we can't write any more text to `f`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-da8b9c9beff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"To boldly go\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# \\n starts a newline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "f.write(\"To boldly go\\n\") # \\n starts a newline\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should **always** close files after you have opened them. However, there is a nice syntactical way to avoid having to remember to do this, using the `with` keyword: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_file2.txt\", \"w\") as f:\n",
    "    f.write(\"to boldly go\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the `with` keyword as temporarily assigning the name `f` within a local scope. Once the local scope terminates, the variables created within that scope are discarded. This process has the convenient effect of automatically closing `f` for us. You should usually use `with` rather than `open()` and `f.close()` unless there are concrete requirements otherwise. \n",
    "\n",
    "A very common pattern is to loop over data and write it line-by-line to a file. Here's an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {\"Chihiro\" : \"Spirited Away\",\n",
    "     \"Ashitaka\" : \"Princess Mononoke\",\n",
    "     \"Sophie\" : \"Howl's Moving Castle\"}\n",
    "\n",
    "with open(\"movies.txt\", \"w\") as f:\n",
    "    for key, val in D.items():\n",
    "        f.write(key + \" is the protagonist of \" + val + \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the `\"w\"` argument to `open()` will erase an existing file `movies.txt` if one exists. To append to the file, use mode `\"a\"` instead:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movies.txt\", \"a\") as f:\n",
    "    f.write(\"Satsuki and Mei are the protagonists of My Neighbor Totoro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "Reading data is not difficult, provided that you can remember iterators. The `f.readline()` method returns the current line of the file and then advances to the next line, very similar to the `__next__()` method of iterators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chihiro is the protagonist of Spirited Away.\n",
      "Ashitaka is the protagonist of Princess Mononoke.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"movies.txt\", \"r\") as f:\n",
    "    print(f.readline(), end = \"\")\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that you can conveniently iterate using a `for`-loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chihiro is the protagonist of Spirited Away.\n",
      "Ashitaka is the protagonist of Princess Mononoke.\n",
      "Sophie is the protagonist of Howl's Moving Castle.\n",
      "Satsuki and Mei are the protagonists of My Neighbor Totoro"
     ]
    }
   ],
   "source": [
    "with open(\"movies.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        print(line, end = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Files\n",
    "\n",
    "`CSV` standands for \"comma-separated values,\" and it is a common format for representing tabular data. A raw `CSV` file might look like this: \n",
    "\n",
    "```csv\n",
    "\n",
    "\"Picard\", \"TNG\", \"Enterprise D\" \n",
    "\"Kirk\", \"TOS\", \"Enterprise A\"\n",
    "\"Janeway\", \"VOY\", \"Voyager\"\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "\n",
    "Python offers a `csv` module that offers some utilities for reading and writing `CSV` files. For example, let's take a quick peek at the [Palmer penguins] data set, which were collected by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a member of the [Long Term Ecological Research Network](https://lternet.edu/). I downloaded these data from [Kaggle](https://www.kaggle.com/), an excellent source of interesting data sets. The file `palmer_penguins.csv` can be downloaded from [this link](https://philchodrow.github.io/PIC16A/content/IO_and_modules/IO/palmer_penguins.csv). It is necessary to place the file `palmer_penguins.csv` in the same directory as this notebook. \n",
    "\n",
    "<figure class=\"image\" style=\"width:50%\">\n",
    "  <img src=\"https://allisonhorst.github.io/palmerpenguins/man/figures/lter_penguins.png\" alt=\"Three stylized penguins, one each of the species Adelie, Gentoo, and Chinstrap, with labels above their heads and patches of color behind them.\">\n",
    "  <figcaption><i>Illustrations of the penguins in the Palmer Penguins data set, by Allison Horst.</i></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studyName', 'Sample Number', 'Species', 'Region', 'Island']\n",
      "['PAL0708', '1', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '2', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '3', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '4', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '5', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '6', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '7', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '8', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n",
      "['PAL0708', '9', 'Adelie Penguin (Pygoscelis adeliae)', 'Anvers', 'Torgersen']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"palmer_penguins.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in list(reader)[0:10]:\n",
    "        print(row[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write new CSV files. For example, let's make a subset file that only includes Adelie Penguins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"palmer_penguins.csv\", \"r\") as original: \n",
    "    with open(\"palmer_penguins_subset.csv\", \"w\") as subset: \n",
    "        reader = csv.reader(original)\n",
    "        writer = csv.writer(subset)\n",
    "        \n",
    "        for row in reader: \n",
    "            if row[2] == \"Adelie Penguin (Pygoscelis adeliae)\":\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the file `palmer_penguins_subset.csv` and observe that all rows in the new data are Adelie penguins. \n",
    "\n",
    "While it is possible to use the `csv` module for reading and manipulating tabular data, we will see much more flexible and powerful methods when we introduce the *data frames* paradigm via the `pandas` module. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
